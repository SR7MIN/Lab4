# 实验四
221275021 孙家瑜

## 任务1：每日资金流入和流出情况计算
使用`spark.read.csv`方法加载CSV文件到DataFrame中，并确保正确解析列类型（如日期、数值等）。
将DataFrame转换为RDD，以便更灵活地进行自定义转换。
映射每行数据到 `(日期, (购买金额, 赎回金额))` 的格式。
按日期聚合，计算每天的资金流入（购买金额总和）和流出（赎回金额总和）。
对结果按日期排序，以保证输出的时间顺序。

## 任务2：活跃用户分析及城市流量统计
### 2.1
分别加载交易表 (`user_balance_table.csv`) 和用户信息表 (`user_profile_table.csv`) 到两个独立的DataFrame中，确保日期字段被正确解析为日期类型，其他数值字段也被正确识别。
使用`join`方法基于`user_id`将两个DataFrame合并，得到包含用户信息和交易记录的完整数据集。
过滤出特定日期（例如2014年3月1日）的数据，按城市分组，计算每个城市的平均余额，按平均余额降序排列，并显示结果。

### 2.2
过滤出特定月份（例如2014年8月）的数据，按城市和用户ID分组，计算每位用户的总流量（购买金额+赎回金额）。
使用窗口函数`row_number`对每个城市的用户按总流量排名，筛选出排名前3的用户，并按城市和排名排序。

## 任务3：暂未完成

## 改进之处
### 1、可以增加更多的异常检测，以防止实验中出现问题时无法定位问题
### 2、对于大规模数据集，考虑增加分区数量以提高并行度，或者应用其他性能优化策略（如广播变量、缓存中间结果等）
